---
title: "Data Analysis"
author: "Chloe Barnes"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
firearm_data_cleaned <- read_excel("../Data/processed/firmarm_data_cleaned.xlsx")
```

```{r}
library(tidyverse)
library(readxl)
library(caret)
library(glmnet)
library(randomForest)
library(cluster)
library(factoextra)
library(keras3)
library(lme4)
library(broom)
library(corrplot)
```

## Load Data
```{r}
data <- firearm_data_cleaned
```


## Research Question 1:
Can we predict firearm death rates based on gun law characteristics

```{r}
# Prepare modeling dataset
model_data <- data %>%
  select(rate, year, state, state_name, law_strength_score,
         restrictive_laws, permissive_laws,
         restrictive_ratio, permissive_ratio) %>%
  drop_na(rate)
```

```{r}
# Train/test split
set.seed(123)
train_idx <- createDataPartition(model_data$rate, p=0.8, list = FALSE)
train_data <- model_data[train_idx, ]
test_data <- model_data[-train_idx, ]
```

## Model 1: Simple Linear Regression 
```{r}
lm1 <- lm(rate ~ law_strength_score, data = train_data)
summary(lm1)
```
```{r}
# Predictions 
pred_lm1 <- predict(lm1, newdata = test_data)
rmse_lm1 <- sqrt(mean((test_data$rate - pred_lm1)^2))
r2_lm1 <- cor(test_data$rate, pred_lm1)^2

print(rmse_lm1)
print(r2_lm1)
```
## Model 2: Multiple Linear Regression
```{r}
lm2 <- lm(rate ~ law_strength_score + restrictive_laws + permissive_laws + year, data = train_data)
summary(lm2)
```
```{r}
# Predictions

pred_lm2 <- predict(lm2, newdata = test_data)
rmse_lm2 <- sqrt(mean((test_data$rate - pred_lm2)^2))
r2_lm2 <- cor(test_data$rate, pred_lm2)^2

print(rmse_lm2)
print(r2_lm2)
```
```{r}
# Check assumptions
par(mfrow = c(2, 2))
plot(lm2, main = "Model 2 Diagnostics")
par(mfrow = c(1, 1))
```
## Model 3: K-Nearest Neighbors

```{r}
knn_features <- c("year", "law_strength_score", "restrictive_laws", "permissive_laws")
knn_train <- train_data %>% select(all_of(knn_features))
knn_test <- test_data %>% select(all_of(knn_features))
```

```{r}
# Scale features
preprocess <- preProcess(knn_train, method = c("center", "scale"))
knn_train_scaled <- predict(preprocess, knn_train)
knn_test_scaled <- predict(preprocess, knn_test)
```

```{r}
# Find optimal k
k_values <- seq(3, 20, by = 2)
knn_results <- data.frame(k = k_values, rmse = NA)

for (i in seq_along(k_values)) {
  knn_model <- knnreg(knn_train_scaled, train_data$rate, k = k_values[i])
  knn_pred <- predict(knn_model, knn_test_scaled)
  knn_results$rmse[i] <- sqrt(mean((test_data$rate - knn_pred)^2))
}

best_k <- knn_results$k[which.min(knn_results$rmse)]
best_knn_rmse <- min(knn_results$rmse)

best_k
best_knn_rmse
```
```{r}
# Plot k optimization
ggplot(knn_results, aes(x = k, y = rmse)) +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(size = 3) +
  geom_vline(xintercept = best_k, linetype = "dashed", color = "red") +
  labs(title = "KNN: Optimal k Selection",
       x = "Number of Neighbors (k)",
       y = "Test RMSE") +
  theme_minimal()
```




































